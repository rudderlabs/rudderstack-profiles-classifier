{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import pathlib\n",
    "import json\n",
    "from logger import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from RedshiftConnector import RedshiftConnector\n",
    "except Exception as e:\n",
    "    logger.warning(f\"Could not import RedshiftConnector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homedir = os.path.expanduser(\"~\")\n",
    "\n",
    "with open(os.path.join(homedir, \".pb/siteconfig.yaml\"), \"r\") as f:\n",
    "    creds = yaml.safe_load(f)[\"connections\"][\"shopify_wh_rs\"][\"outputs\"][\"dev\"]\n",
    "\n",
    "if creds[\"type\"] == \"snowflake\":\n",
    "    print(\n",
    "        f\"Using {creds['schema']} schema in snowflake account: {creds['account']}\"\n",
    "    )\n",
    "elif creds[\"type\"] == \"redshift\":\n",
    "    print(f\"Using {creds['schema']} schema in Redshift account: {creds['host']}\")\n",
    "else:\n",
    "    raise Exception(f\"Unknown database type: {creds['type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector = RedshiftConnector(\"./\")\n",
    "cursor = connector.build_session(creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = \"pages\"\n",
    "tracks = \"tracks\"\n",
    "identifies = \"identifies\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Pages Table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating pages table copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_create_temp = f\"\"\"\n",
    "    CREATE TABLE {pages}_1 \n",
    "    AS (\n",
    "        SELECT \n",
    "            anonymous_id, \n",
    "            user_id, \n",
    "            timestamp as timestamp, \n",
    "            context_campaign_name, \n",
    "            context_campaign_medium, \n",
    "            context_campaign_source, \n",
    "            context_session_id\n",
    "        FROM {pages}\n",
    "    );\n",
    "\"\"\"\n",
    "cursor.execute(query_create_temp)\n",
    "\n",
    "print(\"Created temp tables successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 1\n",
    "data = {\"100k\": 100000, \"500k\": 500000, \"1mn\": 1000000}\n",
    "query_count_row = f\"select count(distinct anonymous_id) from {pages}_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for postfix, limit in data.items():\n",
    "    # reaching limits one by one.\n",
    "    while cursor.execute(query_count_row).fetch_dataframe()['count'][0] <= limit:\n",
    "        query_extend_tmp = f\"\"\"\n",
    "            INSERT INTO {pages}_1 (\n",
    "                (select \n",
    "                    sha1(anonymous_id+{iter}) as anonymous_id, \n",
    "                    sha1(user_id+{iter}) as user_id, \n",
    "                    dateadd(day, CAST(RAND()*28 AS INT), T.timestamp) as timestamp, \n",
    "                    context_campaign_name, \n",
    "                    context_campaign_medium, \n",
    "                    context_campaign_source, \n",
    "                    context_session_id \n",
    "                from {pages}_1 T)\n",
    "            );\n",
    "        \"\"\"\n",
    "        cursor.execute(query_extend_tmp)\n",
    "        iter += 1\n",
    "    \n",
    "    #saving the limit results.\n",
    "    query_save_limit = f\"\"\"\n",
    "        CREATE TABLE {pages}_{postfix}\n",
    "        AS (\n",
    "            SELECT \n",
    "                anonymous_id, \n",
    "                user_id, \n",
    "                timestamp as timestamp, \n",
    "                context_campaign_name, \n",
    "                context_campaign_medium, \n",
    "                context_campaign_source, \n",
    "                context_session_id\n",
    "            FROM {pages}_1\n",
    "        );\n",
    "    \"\"\"\n",
    "    cursor.execute(query_save_limit)\n",
    "    print(f\"Saved {limit} rows successfully in table {pages}_{postfix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping extra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_drop_temp = f\"DROP TABLE {pages}_1\"\n",
    "cursor.execute(query_drop_temp)\n",
    "\n",
    "print(\"Dropped temp tables successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Tracks Table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tracks table copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_create_temp = f\"\"\"\n",
    "    CREATE TABLE {tracks}_1 \n",
    "    AS (\n",
    "        SELECT \n",
    "            anonymous_id, \n",
    "            user_id, \n",
    "            timestamp as timestamp, \n",
    "            context_campaign_name, \n",
    "            context_campaign_medium, \n",
    "            context_campaign_source, \n",
    "            context_session_id\n",
    "        FROM {tracks}\n",
    "    );\n",
    "\"\"\"\n",
    "cursor.execute(query_create_temp)\n",
    "\n",
    "print(\"Created temp tables successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 1\n",
    "data = {\"100k\": 100000, \"500k\": 500000}\n",
    "query_count_row = f\"select count(distinct anonymous_id) from {tracks}_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for postfix, limit in data.items():\n",
    "    # reaching limits one by one.\n",
    "    while cursor.execute(query_count_row).fetch_dataframe()['count'][0] <= limit:\n",
    "        query_extend_tmp = f\"\"\"\n",
    "            INSERT INTO {tracks}_1 (\n",
    "                (select \n",
    "                    sha1(anonymous_id+{iter}) as anonymous_id, \n",
    "                    sha1(user_id+{iter}) as user_id, \n",
    "                    dateadd(day, CAST(RAND()*28 AS INT), T.timestamp) as timestamp, \n",
    "                    context_campaign_name, \n",
    "                    context_campaign_medium, \n",
    "                    context_campaign_source, \n",
    "                    context_session_id \n",
    "                from {tracks}_1 T)\n",
    "            );\n",
    "        \"\"\"\n",
    "        cursor.execute(query_extend_tmp)\n",
    "        iter += 1\n",
    "    \n",
    "    #saving the limit results.\n",
    "    query_save_limit = f\"\"\"\n",
    "        CREATE TABLE {tracks}_{postfix}\n",
    "        AS (\n",
    "            SELECT \n",
    "                anonymous_id, \n",
    "                user_id, \n",
    "                timestamp as timestamp, \n",
    "                context_campaign_name, \n",
    "                context_campaign_medium, \n",
    "                context_campaign_source, \n",
    "                context_session_id\n",
    "            FROM {tracks}_1\n",
    "        );\n",
    "    \"\"\"\n",
    "    cursor.execute(query_save_limit)\n",
    "    print(f\"Saved {limit} rows successfully in table {tracks}_{postfix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping extra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_drop_temp = f\"DROP TABLE {tracks}_1\"\n",
    "cursor.execute(query_drop_temp)\n",
    "\n",
    "print(\"Dropped temp tables successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For identifies Table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating identifies table copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_create_temp = f\"\"\"\n",
    "    CREATE TABLE {identifies}_1 \n",
    "    AS (\n",
    "        SELECT \n",
    "            anonymous_id, \n",
    "            user_id, \n",
    "            email,\n",
    "            timestamp as timestamp, \n",
    "            context_device_name, \n",
    "            context_device_type,\n",
    "            context_device_manufacturer, \n",
    "            context_campaign_source, \n",
    "            address_country,\n",
    "            currency,\n",
    "            state,\n",
    "            first_name,\n",
    "            last_name\n",
    "        FROM {identifies}\n",
    "    );\n",
    "\"\"\"\n",
    "cursor.execute(query_create_temp)\n",
    "\n",
    "print(\"Created temp tables successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 1\n",
    "data = {\"100k\": 100000, \"500k\": 500000, \"1mn\": 1000000}\n",
    "query_count_row = f\"select count(distinct anonymous_id) from {identifies}_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for postfix, limit in data.items():\n",
    "    # reaching limits one by one.\n",
    "    while cursor.execute(query_count_row).fetch_dataframe()['count'][0] <= limit:\n",
    "        query_extend_tmp = f\"\"\"\n",
    "            INSERT INTO {identifies}_1 (\n",
    "                (select \n",
    "                    sha1(anonymous_id+{iter}) as anonymous_id, \n",
    "                    sha1(user_id+{iter}) as user_id,\n",
    "                    sha1(email+{iter}) as email, \n",
    "                    dateadd(day, CAST(RAND()*28 AS INT), T.timestamp) as timestamp, \n",
    "                    context_device_name, \n",
    "                    context_device_type,\n",
    "                    context_device_manufacturer, \n",
    "                    context_campaign_source, \n",
    "                    address_country,\n",
    "                    currency,\n",
    "                    state,\n",
    "                    first_name,\n",
    "                    last_name\n",
    "                from {identifies}_1 T)\n",
    "            );\n",
    "        \"\"\"\n",
    "        cursor.execute(query_extend_tmp)\n",
    "        iter += 1\n",
    "    \n",
    "    #saving the limit results.\n",
    "    query_save_limit = f\"\"\"\n",
    "        CREATE TABLE {identifies}_{postfix}\n",
    "        AS (\n",
    "            SELECT \n",
    "                anonymous_id, \n",
    "                user_id, \n",
    "                email,\n",
    "                timestamp as timestamp, \n",
    "                context_device_name, \n",
    "                context_device_type,\n",
    "                context_device_manufacturer, \n",
    "                context_campaign_source, \n",
    "                address_country,\n",
    "                currency,\n",
    "                state,\n",
    "                first_name,\n",
    "                last_name\n",
    "            FROM {identifies}_1\n",
    "        );\n",
    "    \"\"\"\n",
    "    cursor.execute(query_save_limit)\n",
    "    print(f\"Saved {limit} rows successfully in table {identifies}_{postfix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping extra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_drop_temp = f\"DROP TABLE {identifies}_1\"\n",
    "cursor.execute(query_drop_temp)\n",
    "\n",
    "print(\"Dropped temp tables successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "random",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
