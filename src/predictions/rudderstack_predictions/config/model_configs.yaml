data:
  # Related to the data that is used to train the model
  label_column: is_churned_7_days # Name of the entity_var that needs to be predicted in advance
  label_value: 1 # Value of the label_column when the entity does the event. Not required for regression tasks
  entity_column: user_main_id # Name of the entity defined in the profiles project. Ex: user_id, user_main_id, rudder_id etc
  entity_key: user # Name of the entity key defined in the profiles project. Ex: user, user_main, rudder etc
  output_profiles_ml_model: 'ltv_test'
  task: classification # classification or regression; Can support a few other tasks in the future, like ltv, churn etc which can be super classes of classification/regression.
  index_timestamp: valid_at
  eligible_users: # Can add an sql where condition to filter users. Ex: is_active = 1 and lower(country) = 'us'
  # train_start_dt: '2023-04-24'
  train_start_dt: # The start and end dates can be left empty. If not, the model uses these dates to get historic data for training. 
  # train_end_dt: '2023-05-01'
  train_end_dt:
  prediction_horizon_days: 7 # Days in advance to predict the label_column. 
  user_preference_order_infra: 
    - local
    - rudderstack-infra
    - native-warehouse
  max_row_count: 500000
  recall_to_precision_importance: 1.0 # Importance of recall to precision. If 1.0, then recall and precision are equally important.
  new_materialisations_config:
    strategy: "auto" # (auto|manual) Strategy for generating new materials
    feature_data_min_date_diff: 14 # Required for auto strategy only. Ignored for manual strategy if given. Minimum number of days in the difference between new generated material and existing materials
    max_no_of_dates: 3 # Required for auto strategy only. Ignored for manual strategy if given. Upper limit on how many new materials that can be generated.
    dates: # Required for manual strategy only. Ignored for auto strategy if given
      - '2024-01-01,2024-01-07' # (feature_date, label_date)
      - '2024-01-02,2024-01-08'
      - '2024-01-03,2024-01-09'
  
preprocessing:
  # Related to various preprocessing steps of the data

  timestamp_columns: [] # Timestamp columns get a datediff function applied with the index_timestamp to get days_since_<timestamp_column> features
  
  arraytype_columns: []

  ignore_features: []

  numeric_pipeline:
    numeric_columns: []
    pipeline:
      - name: SimpleImputer
        # strategy can be any acceptable value of sklearn simpleimputer strategy
        missing_values: np.nan
        strategy: constant
        # fill_value: 0
        copy: True
        add_indicator: False
        # keep_empty_features: False

  categorical_pipeline:
    categorical_columns: []
    pipeline:
      - name: SimpleImputer
        strategy: constant
        # if strategy is constant, it expects a fill_value. If that is not returned, it defaults to `unknown`
        fill_value: unknown
        copy: True
        add_indicator: False
      - name: OneHotEncoder
        handle_unknown: ignore
        max_categories: 5 # perform onehot encoding by keeping maximum of these categories per feature. If None, all categories are kept.
  feature_selectors:
    # Feature selectors that get applied after normalizing is done. Has to be from `VarianceThreshold`, `GenericUnivariateSelect`, `chi2`, `f_classif`
    # ToDo: This section is not implemented in the notebook.
    - name: VarianceThreshold
      threshold: 0

  # Train, test, val split ratios. They must be each between 0 and 1, and sum to 1
  train_size: 0.8


train:
  data_path:
    train_file: train.csv
    test_file: test.csv
    val_file: val.csv
    label_col_name: label
  model_params:
    models:
      include :
        classifiers :
          - xgboost # Xgboost Classifier
          - rf      # Random Forest Classifier
          - ada     # AdaBoost Classifier
          - gbc     # Gradient Boosting Classifier
        regressors :
          - xgboost # Xgboost Regressor
          - rf      # Random Forest Regressor
          - ada     # AdaBoost Regressor
          - gbr     # Gradient Boosting Regressor

outputs:
  # Related to the output of the data prep step
  column_names:
    percentile: &percentile_name percentile_score
    score: probability_score
    output_label_column: output_label
  feature_meta_data: 
    features:
      - name: *percentile_name
        description: 'Percentile of churn score. Higher the percentile, higher the probability of churn'

validation:
  model:
    evaluation_metrics:
      - average_precision
      - recall
      - accuracy
    acceptance_criteria:
      # Dev/Stagging model will get accepted if it meets the following criteria
      # Ex.
      #   - average_precision(Dev) > 0.9 * average_precision(Production)
      #   - When above criteria is met, then dev model will be promoted to production
      metric_name: average_precision
      threshold: 0.9