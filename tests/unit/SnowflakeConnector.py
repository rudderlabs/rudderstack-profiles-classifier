# Generated by CodiumAI
from src.predictions.profiles_mlcorelib.connectors.SnowflakeConnector import (
    SnowflakeConnector,
)
import pandas as pd
from unittest.mock import Mock, patch
import unittest
from snowflake.snowpark import Session
import snowflake.snowpark.types as T


class MockSnowflakeConnector(SnowflakeConnector):
    def __init__(self):
        super().__init__({})

    def build_session(self, creds):
        pass


class TestLabelTable(unittest.TestCase):
    def setUp(self) -> None:
        self.connector = MockSnowflakeConnector()
        df = pd.DataFrame.from_dict(
            {
                "COL1": ["2021-01-01 00:00:00", "2021-01-01 00:00:00"],
                "COL2": ["value1", "value2"],
                "COL3": ["2021-01-01", "2021-01-01"],
                "COL4": ["2021-01-01 00:00:00+00:00", "2021-01-01 00:00:00+00:00"],
            }
        )
        session = Session.builder.config("local_testing", True).create()
        self.table = session.create_dataframe(df)
        self.connector.get_table = Mock(return_value=self.table)
        self.label_column = "COL2"
        self.entity_column = "COL3"

    def test_label_table_returns_only_required_cols(self):
        positive_class = "value1"
        actual = self.connector.label_table(
            None, self.label_column, self.entity_column, positive_class
        )
        self.assertListEqual(actual.columns, [self.entity_column, self.label_column])

    def test_label_table_changes_label_value_for_classification(self):
        positive_class = "value1"
        actual = self.connector.label_table(
            None, self.label_column, self.entity_column, positive_class
        )
        actual_label_col_vals = [
            v.as_dict()[self.label_column] for v in actual.collect()
        ]
        expected_label_col_vals = [1, 0]
        self.assertListEqual(actual_label_col_vals, expected_label_col_vals)

    def test_label_table_does_not_change_label_value_for_regression(self):
        actual = self.connector.label_table(
            None, self.label_column, self.entity_column, None
        )
        actual_label_col_vals = [
            v.as_dict()[self.label_column] for v in actual.collect()
        ]
        expected_label_col_vals = ["value1", "value2"]
        self.assertListEqual(actual_label_col_vals, expected_label_col_vals)


class TestSelectRelevantColumns(unittest.TestCase):
    def setUp(self) -> None:
        self.connector = MockSnowflakeConnector()
        df = pd.DataFrame.from_dict(
            {
                "COL1": ["a", "b"],
                "COL2": [1, 2],
                "COL3": [None, None],
                "COL4": ["a1", "b1"],
            }
        )
        session = Session.builder.config("local_testing", True).create()
        self.table = session.create_dataframe(df)

    # Returns a pandas DataFrame with only the columns specified in the training_features_columns dictionary.
    def test_relevant_columns_only(self):
        training_features_columns = ["COL3", "COL2", "COL1"]
        relevant_columns = self.connector.select_relevant_columns(
            self.table, training_features_columns
        )
        expected_columns = ["COL1", "COL2", "COL3"]
        self.assertEqual(list(relevant_columns.columns), expected_columns)

    # Throws an exception that the expected column is not found
    def test_relevant_columns_not_found(self):
        training_features_columns = ["COL1", "COL2", "COL5"]
        with self.assertRaises(Exception) as context:
            self.connector.select_relevant_columns(
                self.table, training_features_columns
            )
        self.assertIn(
            "Expected feature column COL5 not found in the predictions input table",
            str(context.exception),
            [],
        )


class TestJoinInputTables(unittest.TestCase):
    def test_join_input_tables_correct_case(self):
        inputs = [
            {
                "column_name": "is_churned",
                "table_name": "Material_user_var_table_hash_100",
            },
            {
                "column_name": "days_since_last_seen",
                "table_name": "Material_user_var_table_hash_100",
            },
            {
                "column_name": None,
                "table_name": "Material_shopify_user_features_hash_100",
            },
            {
                "column_name": None,
                "table_name": "Material_shopify_sql_model_hash_100",
            },
        ]
        input_columns = ["is_churned", "days_since_last_seen", "COL1", "COL2"]
        entity_column = "user_main_id"
        temp_joined_input_table_name = "temp_joined_input_table"

        connector = MockSnowflakeConnector()
        connector.schema = "schema_name"
        connector.run_query = Mock(return_value=None)
        connector.join_input_tables(
            inputs, input_columns, entity_column, temp_joined_input_table_name
        )

        generated_query = """
                                    CREATE OR REPLACE TABLE schema_name.temp_joined_input_table AS
                                    SELECT t1.user_main_id AS user_main_id, is_churned, days_since_last_seen, COL1, COL2
            FROM
                (SELECT user_main_id, is_churned, days_since_last_seen FROM schema_name.Material_user_var_table_hash_100) t1
    INNER JOIN (SELECT * FROM schema_name.Material_shopify_user_features_hash_100) t2 ON t1.user_main_id = t2.user_main_id
    INNER JOIN (SELECT * FROM schema_name.Material_shopify_sql_model_hash_100) t3 ON t1.user_main_id = t3.user_main_id ;
                                """

        connector.run_query.assert_called_once_with(
            generated_query,
            response=False,
        )


class TestValidations(unittest.TestCase):
    def setUp(self) -> None:
        self.connector = MockSnowflakeConnector()
        df = pd.DataFrame.from_dict(
            {
                "COL1": ["a", "a"],
                "COL2": [1, 2],
                "COL3": [None, None],
                "COL4": ["a1", "b1"],
            }
        )
        self.session = Session.builder.config("local_testing", True).create()
        self.table = self.session.create_dataframe(df)
        self.min_sample_for_training = 3
        self.train_table_pairs = [
            Mock(
                feature_table_name="feature_table_1", label_table_name="label_table_1"
            ),
            Mock(
                feature_table_name="feature_table_2", label_table_name="label_table_2"
            ),
        ]

    # Checks for assertion error if label column is not present in the feature table.
    def test_label_column_not_present(self):
        label_column = "label"
        with self.assertRaises(Exception) as context:
            self.connector.validate_columns_are_present(self.table, label_column)
        self.assertIn(
            f"Label column {label_column} is not present in the feature table.",
            str(context.exception),
            [],
        )

    # Checks if no:of columns in the feature table is less than 3, then it raises an exception.
    @patch(
        "src.predictions.profiles_mlcorelib.utils.constants.CLASSIFIER_MIN_LABEL_PROPORTION",
        new=1.0,
    )
    @patch(
        "src.predictions.profiles_mlcorelib.utils.constants.CLASSIFIER_MAX_LABEL_PROPORTION",
        new=0.0,
    )
    def test_expects_error_if_label_ratios_are_bad_classification(self):
        label_column = "COL2"
        with self.assertRaises(Exception) as context:
            self.connector.validate_class_proportions(
                self.table.select("COL1", "COL2", "COL3"),
                label_column,
                self.train_table_pairs,
            )
        error_msg = "1 - user count:  1 (50.00%)\n\t2 - user count:  1 (50.00%)"
        self.assertIn(
            error_msg,
            str(context.exception),
            [],
        )

    @patch.object(MockSnowflakeConnector, "write_table")
    def test_validate_row_count_insufficient_data(self, mock_write_table):
        with self.assertRaises(Exception) as context:
            self.connector.validate_row_count(
                self.table, self.min_sample_for_training, self.train_table_pairs
            )

        mock_write_table.assert_called_once_with(
            self.table, self.connector.feature_table_name, write_mode="overwrite"
        )

        expected_error_msg = (
            f"Insufficient data for training. Only {self.table.count()} user records found, "
            f"while a minimum of {self.min_sample_for_training} user records is required.\n"
            f"For further information, you can check the table in the warehouse with the name: {self.connector.feature_table_name}.\n"
            f"Following are the table pairs used for creating the training data:\n"
            f" Feature table name, label table name:\n"
            f" feature_table_1, label_table_1\n"
            f" feature_table_2, label_table_2\n"
            f"The table {self.connector.feature_table_name} is built by joining the pairs using the entity-id, concatenating them, and applying eligible users flag. You can try different eligible users conditions to rerun the model to solve the data validation errors."
        )
        self.assertIn(expected_error_msg, str(context.exception))

    def test_expects_error_if_label_count_is_low_regression(self):
        label_column = "COL1"
        with self.assertRaises(Exception) as context:
            self.connector.validate_label_distinct_values(
                self.table, label_column, self.train_table_pairs
            )
            distinct_values_count = self.table.groupBy(label_column).count()
            num_distinct_values = distinct_values_count.count()
            self.assertIn(
                f"Label column {label_column} has {num_distinct_values} distinct values",
                str(context.exception),
                [],
            )

    @patch(
        "src.predictions.profiles_mlcorelib.utils.constants.CLASSIFIER_MIN_LABEL_PROPORTION",
        new=0.05,
    )
    @patch(
        "src.predictions.profiles_mlcorelib.utils.constants.CLASSIFIER_MAX_LABEL_PROPORTION",
        new=0.95,
    )
    def test_passes_for_good_data_classification(self):
        df = pd.DataFrame.from_dict(
            {
                "COL1": ["a", "a", "b"],
                "COL2": [1, 2, 3],
                "COL3": [None, None, None],
                "COL4": ["a1", "b1", "c1"],
            }
        )
        table = self.session.create_dataframe(df)
        self.assertTrue(self.connector.validate_columns_are_present(table, "COL1"))
        self.assertTrue(
            self.connector.validate_class_proportions(
                table, "COL1", self.train_table_pairs
            )
        )

    @patch(
        "src.predictions.profiles_mlcorelib.utils.constants.REGRESSOR_MIN_LABEL_DISTINCT_VALUES",
        new=3,
    )
    def test_passes_for_good_data_regression(self):
        df = pd.DataFrame.from_dict(
            {
                "COL1": [1, 2, 3, 4],
                "COL2": [1, 2, 3, 4],
                "COL3": [None, None, None, None],
                "COL4": ["a1", "b1", "c1", "d1"],
            }
        )
        table = self.session.create_dataframe(df)
        self.assertTrue(self.connector.validate_columns_are_present(table, "COL1"))
        self.assertTrue(
            self.connector.validate_label_distinct_values(
                table, "COL1", self.train_table_pairs
            )
        )
